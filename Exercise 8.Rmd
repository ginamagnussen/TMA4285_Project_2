---
title: "TMA4285 Time series models"
subtitle: "Exercise 8: Comparison of a state space model and a SARIMA model"
author: "Sivert Selnes, Kristine L. Mathisen, Gina Magnussen"
date: "20th of October 2018"
output: 
  pdf_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r}
# Libraries
library(astsa)
library(forecast)
library(ggplot2)
library(dlm)
library(KFAS)
library(zoo)
library(boot)
# libraries for state-space: dse, dlm, KFAS, stsm
```

#### Remember:

* Note how uncertainty should be written: 0.056(7) (See sources on web page)

# Structure
## Title
## Abstract 
## Introduction
## Theory
```{r, child='theory.Rmd'}

```

---------------------------------------------------------

## Data analysis


## 1. Exploring the data with plotting of relevant statistics
## 2. Justification of the choice of model
## 3. Model parameter estimation including uncertainty 
<!-- Simulation -->
## 4. Model prediction at the given sample points and for the next year including uncertainty of the best linear predictions
<!-- Forecasting -->
## 5. Diagnostics, and model choice discussion including comparison of the two models


## $SARIMA(p,d,q)\times(P,D,Q)_s$ model

The data set consists of total number of international airline passengers, in thousands, for each month from January 1949 to December 1960(reference to data set), giving a total number of $N=144$ observations. 


```{r}
dataseries <- ts(read.table("dataEx8.txt"), frequency = 12)
par(mfrow=c(2,2))
plot(dataseries,main = "Airline passengers (1949-1960)", ylab="Passengers (in thousands)")
boxplot(dataseries~cycle(dataseries), xlab="Date", ylab = "Passengers (in thousands)" ,main ="Monthly international air passengers") # MÃ¥ ikke tas med, men viser litt av strukturen til dataene.
acf(dataseries, lag.max = 50)
pacf(dataseries, lag.max = 50)

```

From the time series plot, this is obviously a non-stationary series as both trend and seasonality is visible in the visualization. Trend is there because the total number of airline passengers on average increases for each month, and seasonality because of the wave-like behaviour of the series. Non-stationarity is further supported by looking at the autocorrelation function, which shows considerable correlation between observations even up to lag $h$ of size $30$, and again a periodic wave-like pattern. Furthermore, the box plot shows both higher mean number of passengers and also higher variance for months 6 to 9 in the year, i.e. June til September.

To investigate the data, we first find a transformation to the time series. A normal transformation is the $\log()$-transformation, which seems to stabilize the multiplicative behaviour of the variance so that the variance is not increasing with time.

```{r}
log_series <- log(dataseries)
diff_series <- diff(log_series)
diff12_series <- diff(diff_series, lag = 12)
#hist(diff12_series)
plot.ts(cbind(log_series, diff_series, diff12_series), main="Transformed and differenced data")
```

?? Check if this is correct, especially $d=1 or 2$.
Secondly, the data is differenced to remove trend. The parameter $d$ is related to trend within a season, and since this trend seems to be removed by differencing once, we try $d = 1$. See the plot in the middle in the figure for transformed and differenced data. As there after differencing once still seems to be a wavy pattern for a seasonol trend equal to the length of a year, i.e. $s = 12$ in a seasonal ARIMA model, a twelfth-order difference is applied (bottom plot in figure transformed and differenced data). The parameter $D$ is related to this trend between seasons, i.e. the trend one can se from one January month to the next, the second and so on. We therefore set $D = 1$. Differencing once indicates linear trend, both within and between the seasons. 

Our model parameter choices can be checked by comparing to the decomposed time series:
```{r}
autoplot(decompose(dataseries, "multiplicative"))
```
which clearly shows linear trend and a season equal to a year.

```{r}

ggtsdisplay(diff12_series)

```


The obtained series after applying the twelfth-order difference seems to be stationary without any trend or seasonality. We can then try to estimate the remaining parameters by considering the ACF and the PACF. This would be done by looking at lags equal to $1s, 2s,...$, $s=12$ to determine $P$ and $Q$ in the seasonal component and by looking at smaller lags in each season to determine $p$ and $q$ in the non-seasonal component. However, we chose to look the AICC criterion and tested models with $d=1$, $D=1$, $s=12$, which is determined before, and $p,q,P,Q < 5$ which is based on looking at the ACF and PACF. In addition we prefer models with smaller parameters for simplicity if they are a good fit.

```{r}
bestfit <- auto.arima(log_series, d=1, D=1, max.p=5,max.q=5, max.P=5, max.Q=5, seasonal=TRUE, ic="aicc", trace=T)
```


```{r, include=FALSE}
fit <- sarima(log_series, 0,1,1,0,1,1,12)
fit$ttable # Gives parameter estimates and their standard deviation
```

Both parameters are significant in the model, and the residual analysis plot shows that our model is a good fit. In addition, the uncertainty of the parameters are given from $\texttt{fit\$ttable}$. Our chosen model is thus $\text{SARIMA}(0,1,1)\times(0,1,1)_{12}$.


When we have found our model, we can do forecasting for the next twelve months. 

```{r, include = FALSE}
library(ggplot2)

# Forevasting
future <- 12
sarima.forecast <- sarima.for(log_series, 24,0,1,1,0,1,1, 12) #sarima.forecast$se
sarima.forecast
forecast_sarima <- forecast(log_series, h = future); log_fitted <- forecast_sarima$fitted

# Check model for given sample pointsS
sarima_frame <- data.frame(dataseries, exp(log_fitted), log_series, log_fitted,  1:144)
colnames(sarima_frame) <- c("original", "fitted", "log_original", "log_fitted", "month")
```


```{r}
ggplot(sarima_frame) + 
  geom_line(aes(month, dataseries, color = "original")) + 
  geom_line(aes(month,fitted , color="fitted")) + 
  labs(title="Original and fitted values for SARIMA", xlab="Months", ylab="Passengers")

```

The fitted data looks good compared to the original data and the forecasting seems to continue the season and trend of the data well. Upper and lower bounds for both $80\%$ and $95\%$ confidence intervals are given from 

```{r}
forecast_sarima
```




### State-space model

We build a state-space model by ??eqref to theory or just use Rfunctions??, which gives the following matrices

```{r, echo=FALSE}
# ap <- log10(AirPassengers) - 2
state_space <- StructTS(dataseries, type = "BSM") # Basic structural model
state_space_log <- StructTS(log_series, type ="BSM")
# state_space$model$T # F in state equation
forecasts <- forecast(state_space_log, h = 50)
#forecasts$lower 
#forecasts$upper
plot(forecasts)
#state_space$model$T # gives the F matrix
#state_space$model$Z # gives the G matrix
```
$F=$
```{r}
print(state_space$model$T)
```
$G=$
```{r}
print(state_space$model$Z)
```

$Q=$
```{r}
print(state_space$model$V)
```
This gives $(\hat\sigma_1^2, \hat\sigma_2^2, \hat\sigma^3_2) = (0.0000, 160.9755,  29.84652)$.



```{r}
print(state_space$model$a)
```


```{r}
model.build <- function(p) {
  return(
    dlmModPoly(2, dV=p[1], dW=p[2:3]) + 
      dlmModSeas(12, dV=p[4])
  )
}
 
#log.air <- log(air) + rnorm(length(log.air), 0, 0.15)
log.air <- log_series
train <- log.air[1:120]
test <- log.air[121:144]
 
model.mle <- dlmMLE(train, parm=c(1, 1, 1, 1), build=model.build)
model.fit <- model.build(model.mle$par)
model.filtered <- dlmFilter(train, model.fit)
model.smoothed <- dlmSmooth(train, model.fit)

n <- 2*12
model.forecast <- dlmForecast(model.filtered, nAhead=n)
 
x <- index(log.air)
a <- drop(model.forecast$a%*%t(FF(model.fit)))
df <- rbind(
  data.frame(x=index(log.air), y=as.numeric(log.air), series="original"),
  #data.frame(x=x[1:120], y=apply(model.filtered$m[-1,1:2], 1, sum), series="filtered"),
  #data.frame(x=x[1:120], y=apply(model.smoothed$s[-1,1:2], 1, sum), series="smoothed"),
  data.frame(x=x[121:144], y=a, series="forecast")
)
g.dlm <- ggplot(df, aes(x=x, y=y, colour=series)) + geom_line()
g.dlm
```

?? Also need to forecast for given sample points here and find uncertainty. ??

## Bootstrap
We bootstrap the estimated parameters for the state space model. 
```{r}
n=length(train)
B=2
estimator=matrix(NA,nrow=4, ncol = B)
for (b in 1:B)
  {
  boot=sample(x=log_series,size=n,replace=TRUE)
  model = dlmMLE(boot, parm=c(1, 1, 1, 1), build=model.build)
  estimator[,b] = model$par
}
sd(estimator)
```

* Model diagnostics for state-space? I don't know. \\
* Model comparison + discussion. \\
* Theory \\
??

-------------------------------------------


## Discussion
## Conclusion
## Appendix
## References

