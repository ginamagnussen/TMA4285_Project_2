---
title: "TMA4285 Time series models"
subtitle: "Exercise 8: Comparison of a state space model and a SARIMA model"
author: "Sivert Selnes, Kristine L. Mathisen, Gina Magnussen"
date: "20th of October 2018"
output: 
  pdf_document:
    #fig_caption: true
    #toc: true
    
#header-includes:
#    - \usepackage{caption}

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r}
# Libraries
library(astsa)
library(forecast)
library(ggplot2)
library(dlm)
library(KFAS)
library(zoo)
library(boot)
# libraries for state-space: dse, dlm, KFAS, stsm
```

#### Remember:

* Note how uncertainty should be written: 0.056(7) (See sources on web page)

## Abstract 
In this exercise, we analyse a time series which contain the number of international airline passengers every month for 12 years. The series is first explored with SARIMA, and then explored using state-space models. Finally, the two models are compared. 

## Introduction
The analysis on time series can be used for multiple purposes. In this exercise it will be used to present the data in a way that is easy to interpret. In addition, we use it to do forecasting. The modeling includes a seasonal component that repeats every $s$ observation (every 12th in our data set). This makes the model more precise for time series which has seasonal trends and periodic variations. 


## Theory
```{r, child='theory.Rmd'}
```


## Data analysis


### SARIMA$(p,d,q)\times(P,D,Q)_s$ model

The data set consists of total number of international airline passengers, in thousands, for each month from January 1949 to December 1960 (reference to data set), giving a total number of $N=144$ observations. 


```{r}
dataseries <- ts(read.table("dataEx8.txt"), frequency = 12)
par(mfrow=c(2,2))
plot(dataseries,main = "Airline passengers (1949-1960)", ylab="Passengers (in thousands)")
boxplot(dataseries~cycle(dataseries), xlab="Date", ylab = "Passengers (in thousands)",
        main ="Monthly international air passengers") 
acf(dataseries, lag.max = 50)
pacf(dataseries, lag.max = 50)
```

From the time series plot, this is obviously a non-stationary series as both trend and seasonality is visible in the visualization. Trend is there because the total number of airline passengers on average increases for each month, and seasonality because of the wave-like behaviour of the series. Non-stationarity is further supported by looking at the autocorrelation function, which shows considerable correlation between observations even up to lag $h$ of size $30$, and again a periodic wave-like pattern. Furthermore, the box plot shows both higher mean number of passengers and also higher variance for months 6 to 9 in the year, i.e. June til September.

To investigate the data, we first find a transformation to the time series. A typical transformation for making the series more stationary is the $\log()$-transformation. This seems to stabilize the multiplicative behaviour of the variance so that the variance is not increasing with time.

```{r}
# Log-transform the data
log_series <- log(dataseries)
# Differencing the data
diff_series <- diff(log_series)
diff12_series <- diff(diff_series, lag = 12)

# Plotting the transformed data series
plot.ts(cbind(log_series, diff_series, diff12_series), main="Transformed and differenced data")
```

Secondly, the data is differenced to remove trend, i.e. stabilizing the mean. The parameter $d$ is related to trend within a season, and since this trend seems to be removed by differencing once, we try $d = 1$. See the plot in the middle of the figure for transformed and differenced data. After differencing there still is a wave pattern present, one for each year. This indicates a seasonal trend equal to the length of a year, i.e. we suspect a $s = 12$ in a seasonal ARIMA model. Then $(1-B^{12})$ is applied to the series. The parameter $D$ is related to the trend between seasons, i.e. the trend one can se from one time of the year to the next, and the next, and so on. We therefore set $D = 1$. Differencing once indicates linear trend, both within and between the seasons. 

Our model parameter choices can be checked by comparing to the decomposed time series:
```{r}
autoplot(decompose(dataseries, "multiplicative"))
```
which clearly shows linear trend and a season equal to a year.

```{r}
ggtsdisplay(diff12_series)
```

The obtained series after differencing the second time seems stationary without any trend or seasonality. We can then estimate the remaining parameters by considering the ACF and the PACF. This could be done by looking at lags equal to $1s, 2s,...$, $s=12$ to determine $P$ and $Q$ in the seasonal component and by looking at smaller lags in each season to determine $p$ and $q$ in the non-seasonal component.  In this case, however, we have used the AICC criterion and tested models with $d=1$, $D=1$, $s=12$, which is determined before, and $p,q,P,Q < 5$ which is based by looking at the ACF and PACF. In addition we prefer models with smaller parameters for simplicity if they are a good fit.

The \texttt{auto.arima()}-function tests a variety of models and chooses the best one given our chosen criteria:

```{r}
bestfit <- auto.arima(log_series, d=1, D=1, max.p=5,max.q=5, max.P=5, max.Q=5, seasonal=TRUE, ic="aicc", trace=T)
```

The chosen model with the lowest AICC sets $p=0, q=1, P=0$ and $Q=1$. Fitting this model gives the following result:


```{r, include=FALSE}
fit <- sarima(log_series, 0,1,1,0,1,1,12)
fit$fit
fit$ttable # Gives parameter estimates and their standard deviation

# Bootstrap

n=length(log_series)
B=10
estimator=matrix(NA,nrow=2, ncol = B)
# Bootstrap sample, store parameter vector

for (b in 1:B)
  {
  boot=sample(x=log_series,size=n,replace=TRUE)
  model = sarima(boot, 0,1,1,0,1,1,12)
  estimator[,b] = model$ttable[,1]
}

# Find mean and variance of each parameter
mean = rowMeans(estimator) 
variance = rep(NA,2)
for (p in 1:2){
  variance[p] = var(estimator[p,])
}


```


Both parameters are significant in the model, and the residual analysis plot shows that our model is a good fit. In addition, the uncertainty of the parameters are given from $\texttt{fit\$ttable}$. 
However, when trying to bootstrap the to estimate the uncertainty of the parameters, we don't get the same results. The first line are supposed to be the parameter estimates, and the second line the standard errors.

```{r}
mean
sqrt(variance)
```


We nevertheless choose our model to be 

\[
\text{SARIMA}(0,1,1)\times(0,1,1)_{12} 
\]

which is equal to

\[
\phi(B)\Phi(B^{12})(1-B)(1-B^{12})X_t = \theta(B)\Theta(B^{12})Z_t
\]

When we have found our model, we can do forecasting with the SARIMA model for the next twelve months. From the fitting functions in R, we can also extract credible intervals of the forecasts and the fitted values at our given sample points.

```{r}

# Forecasting
future <- 12 # Set no. of months to forecast
# Forecasting
forecast_sarima <- forecast(log_series, h = future) # Forecastin
log_fitted <- forecast_sarima$fitted # Fitted values for already given sample points

# Check model for given sample points
sarima_frame <- data.frame(dataseries, exp(log_fitted), log_series, log_fitted,  1:144)
colnames(sarima_frame) <- c("original", "fitted", "log_original", "log_fitted", "month")
```

The following plot shows the time series and the forecased values for the next twelve months: 

```{r}
plot(forecast_sarima)
```

The credible intervals for the forecasts are

```{r}
uncertainty <- data.frame("95percent_lower" = exp(forecast_sarima$lower)[,2], "95percent_upper"=exp(forecast_sarima$upper)[,2])
uncertainty

```


```{r}
ggplot(sarima_frame) + 
  geom_line(aes(month, dataseries, color = "original")) + 
  geom_line(aes(month,fitted , color="fitted")) + 
  labs(title="Original and fitted values for SARIMA", xlab="Months", ylab="Passengers")
```

The fitted data looks good compared to the original data and the forecasting seems to continue the season and trend of the data well. 



### State-space model

We build a state-space model, which gives the following matrices

```{r}
# ap <- log10(AirPassengers) - 2
state_space <- StructTS(dataseries, type = "BSM") # Basic structural model
state_space_log <- StructTS(log_series, type ="BSM")
# state_space$model$T # F in state equation
forecasts <- forecast(state_space_log, h = 12)
#forecasts$lower 
#forecasts$upper
plot(forecasts)
#state_space$model$T # gives the F matrix
#state_space$model$Z # gives the G matrix
```
$F=$
```{r}
print(state_space$model$T)
```
$G=$
```{r}
print(state_space$model$Z)
```

$Q=$
```{r}
print(state_space$model$V)
```
This gives $(\hat\sigma_1^2, \hat\sigma_2^2, \hat\sigma^3_2) = (0.0000, 160.9755,  29.84652)$.



```{r}
print(state_space$model$a)
```


```{r}
# State space with DLM method

model.build <- function(p) {
  return(
    dlmModPoly(2, dV=p[1], dW=p[2:3]) + 
      dlmModSeas(12, dV=p[4])
  )
}
 
#log.air <- log(air) + rnorm(length(log.air), 0, 0.15)
log.air <- log_series
train <- log.air[1:120]
test <- log.air[121:144]
 
model.mle <- dlmMLE(train, parm=c(1, 1, 1, 1), build=model.build)
model.fit <- model.build(model.mle$par)
model.filtered <- dlmFilter(train, model.fit)
model.smoothed <- dlmSmooth(train, model.fit)

n <- 2*12
model.forecast <- dlmForecast(model.filtered, nAhead=n)
 
x <- index(log.air)
a <- drop(model.forecast$a%*%t(FF(model.fit)))
df <- rbind(
  data.frame(x=index(log.air), y=as.numeric(log.air), series="original"),
  #data.frame(x=x[1:120], y=apply(model.filtered$m[-1,1:2], 1, sum), series="filtered"),
  #data.frame(x=x[1:120], y=apply(model.smoothed$s[-1,1:2], 1, sum), series="smoothed"),
  data.frame(x=x[121:144], y=a, series="forecast")
)
g.dlm <- ggplot(df, aes(x=x, y=y, colour=series)) + geom_line()
g.dlm
```


### Bootstrap
We bootstrap to estimate the and find the uncertainty of the parameters for the state space model.

```{r, include=FALSE}
n=length(log_series)
B=10
estimator=matrix(NA,nrow=4, ncol = B)
# Bootstrap sample, store parameter vector
for (b in 1:B)
  {
  boot=sample(x=log_series,size=n,replace=TRUE)
  model = dlmMLE(boot, parm=c(1, 1, 1, 1), build=model.build)
  estimator[,b] = model$par
}

# Find mean and variance of each parameter
mean = rowMeans(estimator) 
variance = rep(NA,4)
for (p in 1:4){
  variance[p] = var(estimator[p,])
}

```

The estimated parameters and their uncertainties are respectively

```{r}
mean 
variance
```

?? Ser ikke helt at dette heller stemmer overens med det vi får fra modellen... ?? 

## Discussion
- Får til å sette opp begge modeller, men vi har kun fått testet om SARIMA-modellen er god, ikke for state-space.
- Får ikke helt til bootstrapping/simulering for å estimere parametre og deres usikkerhet for modellene, men vi har gjort et forsøk. Se appendix.
- State-space variablene stemmer heller ikke overens med de resultatene som står i læreboka, så det er vanskelig å avgjøre om modellen er god? (Hva tenkes om dette punktet?)

## Conclusion
- Som følge av punktene ovenfor foretrekker vi SARIMA-modellen. 

## Appendix
## Reference
Brockwell, Peter J., Davis, Richard A. 2002. $\textit{Introduction to time series and forecasting}$. 2nd ed. New York: Springer Science
---------------------------------------------------------

-------------------------------------------



